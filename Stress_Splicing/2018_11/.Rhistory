
exp_data = exp_data[order(exp_data$sampleID),]
### Finding invalid observations ###
# Find invalid observations - Find counts of each unique sampleID; remove ones with count not equal to 2 from data frame
counts = as.data.frame(table(exp_data$sampleID))
countsne2 = as.data.frame(filter(counts, !counts$Freq==2))
countsne2$Var1 = as.numeric(as.character(countsne2$Var1))
# Remove observations with count not equal to 2 from data set
exp_data = exp_data[!exp_data$sampleID %in% countsne2$Var1,]
# Create empty vectors for for-loop to input cpD1 values
test1.exp = c()
allP.exp = c()
sampleID.exp = c()
# For loop -- iterating thru starting quantity and reaction type to return cpD1 values
for(i in 1:length(exp_data$sampleID)){
id.exp = toString(exp_data$sampleID[i])
if(i %% 2 == 1){
sampleID.exp = c(sampleID.exp, id.exp)

}
print(divide(group$k$a, group$k$b))
for (k in names){
#print(divide(group$k$a, group$k$b))
print(group$k)
}
group$names[1]
names[1]
group$(names[1])
#for each group in k, divide column a by column b
names = c(x, y, z)
#for each group in k, divide column a by column b
names = c('x', 'y', 'z')
for (k in names){
#print(divide(group$k$a, group$k$b))
print(group$k)
}
for (k in names){
#print(divide(group$k$a, group$k$b))
print(k)
}

group$'x'
group$"x"
for (k in names){
#print(divide(group$k$a, group$k$b))
print(group$k)

# Bind test1 and allProd cpD1 values by sample ID, convert to data frame
exp_data = as.data.frame(cbind(sampleID.exp, test1.exp, allP.exp))
exp_data$test1.exp = as.numeric(as.character(exp_data$test1.exp))
exp_data$allP.exp = as.numeric(as.character(exp_data$allP.exp))
#write.csv(exp_data, file = "exp_2018_11.csv")
### COMPLETED EXPERIMENTAL DATA FRAME ###
##########################################################
##finding ajustment value##
group = split.data.frame(calib_data, calib_data$startq)
adj <- function(AllP, Test1){
adjust = ave(AllP)-ave(Test1)
return(adjust)

}
print(k)
group$k
group$print(k)
for (k in group){
print(divide(group$k$a, group$k$b))
print(group$k)
}
for (k in group){
#print(divide(group$k$a, group$k$b))
print(group$k)
}
for (k in group){
#print(divide(group$k$a, group$k$b))
print(k)
}
k
k$a
k$a/k$b
divide(k$a, k$b)
k$a
k$a[1]
k$a[1]/k$b
k$a[2]/k$b
for (k in group){
print(divide(k$a, k$b))
print(k)
}
divide(k$a, k$b)
k$a
class(k$a)
for (k in group){
print(divide(c(k$a), c(k$b)))
#print(k)
}
divide(m$a, m$b)
class(m$a)
for (k in group){
A = k$a
B = k$b
print(divide(A, B))
#print(k)
}
for (k in group){
A = c(k$a)
B = c(k$b)
print(divide(A, B))
#print(k)
}

library(tidyverse)
m %>%
group_by(name) %>%
summarise(a.mean = mean(a))
m %>%
group_by(name) %>%
divide(a/b)
m %>%
group_by(name) %>%
divide(a,b)
gapply(m, name = "x", divide(k$a,k$b))
library(apply)
install.packages("apply")
library(apply)
install.packages("gapply")
library(gapply)
name = c('x','x','y','y','z','z')
a = c(1,2,3,4,5,6)
b = c(7,8,9,10,11,12)
m = data.frame(cbind(name,a,b), stringsAsFactors = FALSE)
# this function divides every item in column 1 by every item in column 2
divide <- function(col1, col2){
r = c()
for (i in col1){
r = cbind(r,col1[i]/col2)

print(adj.test1.avg)
# used as a key for the adjustment per start q
calib_adj = unique(as.data.frame(cbind(as.numeric(as.character(calib_data$startq)), adj.test1.avg)))
# Rename columns
colnames(calib_adj)=c("startq", "adj.test1.avg")
newratiosvector = na.omit(newratiosvector)
# Remove rows with NA from data frame so zscore can be appended
newratios.calib = na.omit(newratios.calib)
zscore = (newratiosvector - mean(newratiosvector))/sd(newratiosvector)
newratios.calib$zscore = zscore
View(calib_adj)
##########################################################
############## QPCR PLATE & ADJUSTMENT MODEL #############
##########################################################
library(tidyr)
library(pracma)
library(stringr)
library(tidyverse)
library(dplyr)
library(MASS)
library(glm.predict)
library(Stack)
library(rowr)
# Mac Directory
setwd("~/Stapleton_Lab/Stapleton_Lab/Stress_Splicing/2018_11")
#setwd("~/Stapleton_Lab/Stapleton_Lab/Stress_Splicing/2018_(MONTH)")
# PC Directory
#setwd("C:/Users/twili/Desktop/GIThub/StapletonLab/StressSplicing/qPCR")
### READ IN DERIVATIVE DATA ###
# In the case of having two separate CSV files of calculated derivatives,
# use this code to combine, prior to the following transpositions:
deriv.1<-read.csv(file = "2018_11_1_qPCR_Output.csv", header=FALSE)
deriv.2<-read.csv(file = "2018_11_2_qPCR_Output.csv", header=FALSE)
deriv_complete=as.data.frame(cbind(deriv.1, deriv.2))
# In the case of having one CSV containing calculated derivatives, use this code:
#deriv=read.csv(file = "(YEAR_MONTH_PLATE_qPCR_output.csv", header=FALSE)
#deriv=read.csv(file = "2018_06_01_plate_qPCR_output_2019_04_04.csv", header=FALSE)
##########################################################
################### Initial Data Framing #################
##########################################################
deriv = deriv_complete
# Remove extra column
deriv = deriv[,-1]
# Transpose derivatives to be in equivalent format as raw plate data
deriv = as.data.frame(t(deriv), header=TRUE)
# Rename columns
colnames(deriv)=c("plateID", "reaction_type", "sampleID", "starting_quantity", "cpD1", "cpD2")
### Removing NTC and gblock-Minus values ###
# Indicate if sample is NTC (negative control)
deriv['sampleID_NTC'] = grepl('NTC', deriv$sampleID)
# Remove NTC samples, indicator (T/F) column, and cpD2 values
ntc = which(deriv$sampleID_NTC)
deriv = deriv[-ntc,]
deriv = deriv[,-c(6,7)]
# Indicate if sample is 'Plus' or 'Minus'
deriv['sampleID_Minus'] = grepl('minus', deriv$sampleID)
# Remove 'Minus' values (include only gblock+ values), and indicator (T/F) column
minus = which(deriv$sampleID_Minus)
# IF "minus" RETURNS EMPTY VALUES, COMMENT OUT COMMAND BELOW
deriv = deriv[-minus,]
deriv = deriv[,-6]
# Remove two extra label rows from center of data frame
deriv['label.row'] = grepl('3', deriv$starting_quantity)
extra = which(deriv$label.row)
deriv = deriv[-extra,]
deriv = deriv[,-6]
deriv$cpD1 = as.numeric(as.character(deriv$cpD1))
### COMPLETED INITIAL DATA FRAMING ###
##########################################################
############ Removing Ununsual Observations ##############
##########################################################
# Remove unusual observations from initial data frame (CT value less than 10)
deriv = deriv %>% filter(deriv$cpD1 >= 10)
# Read in raw cycle data - may need to combine multiple files
cycle1 = read.csv(file = "2018_11_1_plate.csv", header = FALSE)
cycle2 = read.csv(file = "2018_11_2_plate.csv", header = FALSE)
cycle = as.data.frame(cbind(cycle1, cycle2))
# Create complete set of reaction data (derivative and cycle)
reaction = Stack(deriv_complete, cycle1)
# Remove repeat labeling
replace = reaction[7:10,]
reaction = reaction[-c(1:4, 7:10),]
reaction = Stack(replace, reaction)
# Transpose so column headers at top
reaction = as.data.frame(t(reaction))
reaction = reaction[,-c(6:7)]
# Replace column names with first row
colnames(reaction) <- as.character(unlist(reaction[1,]))
reaction = reaction[-1,]
colnames(reaction)[5] = "cpD1"
reaction$cpD1 = as.numeric(as.character(reaction$cpD1))
# Filter unusual observations (CT value less than 10)
unusual_obs_2018_11 = reaction %>% filter(reaction$cpD1 < 10)
# Write CSV file
#write.csv(unusual_obs_2018_11, file="Unusual_Obs_2018_11.csv")
### COMPLETED UNUSUAL OBSERVATIONS REMOVAL/REPORTING ###
##########################################################
################# Calibrated Data Framing ################
##########################################################
# Create/Write data frame for Calibrated values
calib_data = deriv %>% filter(str_detect(sampleID, "g"))
# Sort by starting quantity
calib_data = calib_data[order(calib_data$starting_quantity),]
calib_data$starting_quantity = as.numeric(as.character(calib_data$starting_quantity))
calib_data$cpD1 = as.numeric(as.character(calib_data$cpD1))
test1 = filter(calib_data, reaction_type=="test1")[,5]
allP = filter(calib_data, reaction_type=="all_products")[,4:5]
# Combine test1 and allP obs, with NA in blank cells
calib_data = as.data.frame(cbind.fill(allP, test1, fill = NA))
colnames(calib_data) = c("startq", 'allP', "test1")
# Format starting quantity values as decimals, not scientific notation
calib_data$startq=as.factor(format(calib_data$startq, scientific=FALSE))
calib_data$startq=as.factor(calib_data$startq)
#write.csv(calib_data, file = "calib_2018_11.csv")
### COMPLETED CALIBRATED DATA FRAME ###
##########################################################
############### Experimental Data Framing ################
##########################################################
# Create/Write data frame for Experimental values
exp_data = deriv %>% filter(str_detect(sampleID, "g")==FALSE)
# Sort by starting quantity
exp_data = exp_data[order(exp_data$starting_quantity),]
# # Remove first and last rows (unnecessary labeling)
# exp_data = exp_data[-1,]
# exp_data = exp_data[-nrow(exp_data),]
exp_data$cpD1 = as.numeric(as.character(exp_data$cpD1))
# Order data by sampleID
exp_data = exp_data[order(exp_data$sampleID),]
### Finding invalid observations ###
# Find invalid observations - Find counts of each unique sampleID; remove ones with count not equal to 2 from data frame
counts = as.data.frame(table(exp_data$sampleID))
countsne2 = as.data.frame(filter(counts, !counts$Freq==2))
countsne2$Var1 = as.numeric(as.character(countsne2$Var1))
# Remove observations with count not equal to 2 from data set
exp_data = exp_data[!exp_data$sampleID %in% countsne2$Var1,]
# Create empty vectors for for-loop to input cpD1 values
test1.exp = c()
allP.exp = c()
sampleID.exp = c()
# For loop -- iterating thru starting quantity and reaction type to return cpD1 values
for(i in 1:length(exp_data$sampleID)){
id.exp = toString(exp_data$sampleID[i])
if(i %% 2 == 1){
sampleID.exp = c(sampleID.exp, id.exp)

}
return(r)
}
# change the components of the matrix to numeric
m$a = as.numeric(m$a)
m$b = as.numeric(m$b)
# split the matrix by each group
group = split(m, name)
one = group$x
two = group$y
three = group$z
divide(one$a, one$b)
divide(two$a, two$b)
group = split(m, name)
print(group)
one = group$x
two = group$y
three = group$z
divide(two$a, two$b)
two
two = as.data.frame(group$y)
two
divide(two$a, two$b)
A = group$y$a
B = group$y$b
divide(A, B)
### developing code for combination ratios for qPCR ###
name = c('x','x','y','y','z','z')
a = c(1,2,3,4,5,6)
b = c(7,8,9,10,11,12)
m = data.frame(cbind(name,a,b), stringsAsFactors = FALSE)
# this fu
m
# this function divides every item in column 1 by every item in column 2
divide <- function(col1, col2){
r = c()
for (i in col1){
r = cbind(r,col1[i]/col2)
}
return(r)
}
divide(m$a, m$b)
# change the components of the matrix to numeric
m$a = as.numeric(m$a)
m$b = as.numeric(m$b)
divide(m$a, m$b)
# split the matrix by each group
group = split(m, name)
print(group)
for (k in group){
print(divide(k$a, k$b))
#print(k)
}
for (k in group){
print(divide(k$b, k$a))
#print(k)
}
print(divide(k$a, k$b))
for (k in group){
print(divide(k$a, k$b))
#print(k)
}
library(vqtl)
?mean.qtl.dom
??mean.qtl.dom
### developing code for combination ratios for qPCR ###
name = c('x','x','y','y','z','z')
a = c(1,2,3,4,5,6)
b = c(7,8,9,10,11,12)
m = data.frame(cbind(name,a,b), stringsAsFactors = FALSE)
# this function divides every item in column 1 by every item in column 2
divide <- function(col1, col2){
r = c()
for (i in col1){
r = cbind(r,col1[i]/col2)
}
return(r)
}
# change the components of the matrix to numeric
m$a = as.numeric(m$a)
m$b = as.numeric(m$b)
divide(a,b)
# split the matrix by each group
group = split(m, name)
print(group)
for (k in group){
print(divide(k$a, k$b))
#print(k)
}

print(finalg)
#stt grade calc
mid = .74
proj = c(14/15, 1,1,1,1)
final = 1
pres = 1
paper = 1
finalg = sum(mid*0.15, ave(proj)*.45, final*.2, pres*.1, paper*.1)
print(finalg)
mid = 74
proj = c((14/15)*100, 100,100,100,100)
final = 100
pres = 100
paper = 100
finalg = sum(mid*0.15, ave(proj)*.45, final*.2, pres*.1, paper*.1)
print(finalg)
0.15+0.45+0.2+0.1+0.1
ave(proj)
mean(proj)
finalg = sum(mid*0.15, mean(proj)*.45, final*.2, pres*.1, paper*.1)
print(finalg)
mid = 74
proj = c((14/15)*100, 100,100,100,100)
final = 75
pres = 75
paper = 75
finalg = sum(mid*0.15, mean(proj)*.45, final*.2, pres*.1, paper*.1)
print(finalg)
mid = 74
proj = c((14/15)*100, 100,100,100,100)
final = 75
pres = 80
paper = 80
finalg = sum(mid*0.15, mean(proj)*.45, final*.2, pres*.1, paper*.1)
print(finalg)
mid = 74
proj = c((14/15)*100, 100,100,100,100)
final = 75
pres = 90
paper = 90
finalg = sum(mid*0.15, mean(proj)*.45, final*.2, pres*.1, paper*.1)
print(finalg)
14/15
mid = 74
proj = c((14/15)*100, 100,100,100,100)
final = 75
pres = (14/15)*100
paper = (14/15)*100
finalg = sum(mid*0.15, mean(proj)*.45, final*.2, pres*.1, paper*.1)
print(finalg)
#stt grade calc
mid = 74
proj = c((14/15)*100, 100,100,100,100)
final = 80
pres = (14/15)*100
paper = (14/15)*100
finalg = sum(mid*0.15, mean(proj)*.45, final*.2, pres*.1, paper*.1)
print(finalg)
?matrix(
)
m = matrix(c(1,2,3,4,5,6,7,8,9), nrow =3 )
m\
m
flatten(m, across = "rows")
new = as.vector(m)
new
new = as.vector(as.data.frame(m)
)
new
newvector = as.vector(m)
new = as.vector(as.matrix.data.frame(m))
m = matrix(c(1,2,3,4,5,6,7,8,9), nrow =3 )
newvector = as.vector(m)
new = as.vector(as.matrix.data.frame(m))
new
?rep()
?sort()
grades
numLlvs <- 4
confusionMatrix(
factor(sample(rep(letters[1:numLlvs], 200), 50)),
factor(sample(rep(letters[1:numLlvs], 200), 50)))
install.packages("confusionMatrix")
library('caret')
numLlvs <- 4
confusionMatrix(
factor(sample(rep(letters[1:numLlvs], 200), 50)),
factor(sample(rep(letters[1:numLlvs], 200), 50)))
sample(rep(letters[1:numLlvs], 200), 50)
sample(rep(letters[1:numLlvs], 200), 50)
confusionMatrix(
factor(sample(rep(letters[1:numLlvs], 200), 50)),
factor(sample(rep(letters[1:numLlvs], 200), 50)))

print(adj.test1.avg)
# used as a key for the adjustment per start q
calib_adj = unique(as.data.frame(cbind(as.numeric(as.character(calib_data$startq)), adj.test1.avg)))
# Rename columns
colnames(calib_adj)=c("startq", "adj.test1.avg")
calib_subset = na.omit(calib_data[,1:3])
#MODEL COMPARISON#
#StartQ ~ test1
model2 = polr(startq ~ test1,data = calib_subset, Hess=TRUE)
summary(model2)
(ctable <- coef(summary(model2)))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
options(scipen=999)
## combined table
(ctable <- cbind(ctable, "p value" = p))
#StartQ ~ AllP
model3 = polr(startq ~ allP, data = calib_subset, Hess=TRUE)
summary(model3)
(ctable <- coef(summary(model3)))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
options(scipen=999)
## combined table
(ctable <- cbind(ctable, "p value" = p))
#StartQ ~ AllP + test1 -- this model produces some issues in the polr model and won't run
model4 = polr(startq ~ allP + test1, data = calib_subset, Hess=TRUE)
View(calib_subset)
?polr
#StartQ ~ AllP + test1 -- this model produces some issues in the polr model and won't run
model4 = polr(startq ~ allP + test1, data = calib_subset, Hess=TRUE)
summary(model4)
(ctable <- coef(summary(model4)))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
options(scipen=999)
## combined table
(ctable <- cbind(ctable, "p value" = p))

library(tidyr)
library(pracma)
library(stringr)
library(tidyverse)
library(dplyr)
library(MASS)
library(glm.predict)
library(Stack)
library(rowr)

setwd("C:/Users/twili/Desktop/GIThub/Andrew/stapleton_lab/Stress_Splicing/2018_11")

# Mac Directory
setwd("~/Stapleton_Lab/Stapleton_Lab/Stress_Splicing/2018_11")
#setwd("~/Stapleton_Lab/Stapleton_Lab/Stress_Splicing/2018_(MONTH)")
# PC Directory
#setwd("C:/Users/twili/Desktop/GIThub/StapletonLab/StressSplicing/qPCR")
### READ IN DERIVATIVE DATA ###
# In the case of having two separate CSV files of calculated derivatives,
# use this code to combine, prior to the following transpositions:

deriv.1<-read.csv(file = "2018_11_1_qPCR_Output.csv", header=FALSE)
deriv.2<-read.csv(file = "2018_11_2_qPCR_Output.csv", header=FALSE)
deriv_complete=as.data.frame(cbind(deriv.1, deriv.2))
# In t
##########################################################
################### Initial Data Framing #################
##########################################################
deriv = deriv_complete
# Remove extra column
deriv = deriv[,-1]
# Transpose derivatives to be in equivalent format as raw plate data
deriv = as.data.frame(t(deriv), header=TRUE)
# Rename columns
colnames(deriv)=c("plateID", "reaction_type", "sampleID", "starting_quantity", "cpD1", "cpD2")
### Removing NTC and gblock-Minus values ###
# Indicate if sample is NTC (negative control)
deriv['sampleID_NTC'] = grepl('NTC', deriv$sampleID)
# Remove NTC samples, indicator (T/F) column, and cpD2 values
ntc = which(deriv$sampleID_NTC)
deriv = deriv[-ntc,]
deriv = deriv[,-c(6,7)]
# Indicate if sample is 'Plus' or 'Minus'
deriv['sampleID_Minus'] = grepl('minus', deriv$sampleID)
# Remove 'Minus' values (include only gblock+ values), and indicator (T/F) column
minus = which(deriv$sampleID_Minus)
# IF "minus" RETURNS EMPTY VALUES, COMMENT OUT COMMAND BELOW
deriv = deriv[-minus,]
deriv = deriv[,-6]
# Remove two extra label rows from center of data frame
deriv['label.row'] = grepl('3', deriv$starting_quantity)
extra = which(deriv$label.row)
deriv = deriv[-extra,]
deriv = deriv[,-6]
deriv$cpD1 = as.numeric(as.character(deriv$cpD1))
### COMPLETED INITIAL DATA FRAMING ###
##########################################################
############ Removing Ununsual Observations ##############
##########################################################
# Remove unusual observations from initial data frame (CT value less than 10)
deriv = deriv %>% filter(deriv$cpD1 >= 10)
# Read in raw cycle data - may need to combine multiple files
cycle1 = read.csv(file = "2018_11_1_plate.csv", header = FALSE)
cycle2 = read.csv(file = "2018_11_2_plate.csv", header = FALSE)
cycle = as.data.frame(cbind(cycle1, cycle2))
# Create complete set of reaction data (derivative and cycle)
reaction = Stack(deriv_complete, cycle1)
# Remove repeat labeling
replace = reaction[7:10,]
reaction = reaction[-c(1:4, 7:10),]
reaction = Stack(replace, reaction)
# Transpose so column headers at top
reaction = as.data.frame(t(reaction))
reaction = reaction[,-c(6:7)]
# Replace column names with first row
colnames(reaction) <- as.character(unlist(reaction[1,]))
reaction = reaction[-1,]
colnames(reaction)[5] = "cpD1"
reaction$cpD1 = as.numeric(as.character(reaction$cpD1))
# Filter unusual observations (CT value less than 10)
unusual_obs_2018_11 = reaction %>% filter(reaction$cpD1 < 10)
# Write CSV file
#write.csv(unusual_obs_2018_11, file="Unusual_Obs_2018_11.csv")
### COMPLETED UNUSUAL OBSERVATIONS REMOVAL/REPORTING ###
##########################################################
################# Calibrated Data Framing ################
##########################################################
# Create/Write data frame for Calibrated values
calib_data = deriv %>% filter(str_detect(sampleID, "g"))
# Sort by starting quantity
calib_data = calib_data[order(calib_data$starting_quantity),]
calib_data$starting_quantity = as.numeric(as.character(calib_data$starting_quantity))
calib_data$cpD1 = as.numeric(as.character(calib_data$cpD1))
test1 = filter(calib_data, reaction_type=="test1")[,5]
allP = filter(calib_data, reaction_type=="all_products")[,4:5]
# Combine test1 and allP obs, with NA in blank cells
calib_data = as.data.frame(cbind.fill(allP, test1, fill = NA))
colnames(calib_data) = c("startq", 'allP', "test1")
# Format starting quantity values as decimals, not scientific notation
calib_data$startq=as.factor(format(calib_data$startq, scientific=FALSE))
calib_data$startq=as.factor(calib_data$startq)
#write.csv(calib_data, file = "calib_2018_11.csv")
### COMPLETED CALIBRATED DATA FRAME ###
##########################################################
############### Experimental Data Framing ################
##########################################################
# Create/Write data frame for Experimental values
exp_data = deriv %>% filter(str_detect(sampleID, "g")==FALSE)
# Sort by starting quantity
exp_data = exp_data[order(exp_data$starting_quantity),]
# # Remove first and last rows (unnecessary labeling)
# exp_data = exp_data[-1,]
# exp_data = exp_data[-nrow(exp_data),]
exp_data$cpD1 = as.numeric(as.character(exp_data$cpD1))
# Order data by sampleID
exp_data = exp_data[order(exp_data$sampleID),]
### Finding invalid observations ###
# Find invalid observations - Find counts of each unique sampleID; remove ones with count not equal to 2 from data frame
counts = as.data.frame(table(exp_data$sampleID))
countsne2 = as.data.frame(filter(counts, !counts$Freq==2))
countsne2$Var1 = as.numeric(as.character(countsne2$Var1))
# Remove observations with count not equal to 2 from data set
exp_data = exp_data[!exp_data$sampleID %in% countsne2$Var1,]
# Create empty vectors for for-loop to input cpD1 values
test1.exp = c()
allP.exp = c()
sampleID.exp = c()
# For loop -- iterating thru starting quantity and reaction type to return cpD1 values
for(i in 1:length(exp_data$sampleID)){
id.exp = toString(exp_data$sampleID[i])
if(i %% 2 == 1){
sampleID.exp = c(sampleID.exp, id.exp)
}
val = toString(exp_data$reaction_type[i])
if(strcmp(val, "test1")){
test1.exp = c(test1.exp, exp_data$cpD1[i])
}
if(strcmp(val, "all_products")){
allP.exp = c(allP.exp, exp_data$cpD1[i])
}
}
# Bind test1 and allProd cpD1 values by sample ID, convert to data frame
exp_data = as.data.frame(cbind(sampleID.exp, test1.exp, allP.exp))
exp_data$test1.exp = as.numeric(as.character(exp_data$test1.exp))
exp_data$allP.exp = as.numeric(as.character(exp_data$allP.exp))
#write.csv(exp_data, file = "exp_2018_11.csv")
##finding ajustment value##
group = split.data.frame(calib_data, calib_data$startq)
adj <- function(AllP, Test1){
adjust = ave(AllP)-ave(Test1)
return(adjust)
}
adjval = NULL
for (k in group){
adjval = c(adjval,adj(k$allP, k$test1))
}
calib_data$adjval = adjval
calib_data$adjusted_test1 = calib_data$test1 + adjval
##### Finding the average adjusted test 1 #########
#average function takes the mean of each
average <- function(col1){
avg = NULL;
for (i in col1){
avg = c(avg,mean(col1))
}
return(avg)
}
##Subset data by starting quantity
group = split.data.frame(calib_data, calib_data$startq)
adj.test1.avg = NULL;
for (k in group){
adj.test1.avg = c(adj.test1.avg, average(k$adjusted_test1))
}
print(adj.test1.avg)
# used as a key for the adjustment per start q
calib_adj = unique(as.data.frame(cbind(as.numeric(as.character(calib_data$startq)), adj.test1.avg)))
# Rename columns
colnames(calib_adj)=c("startq", "adj.test1.avg")
################################################
##### Creating the components of the ORLM ######
################################################
calib_subset = na.omit(calib_data[,1:3])
#this subset uses the most information without omitting too much data

#zscores of the allp and test1
calib_subset$ztest1 = (calib_subset$test1 - mean(calib_subset$test1))/sd(calib_subset$test1)
calib_subset$zallP = (calib_subset$allP - mean(calib_subset$allP))/sd(calib_subset$allP)
model2 = polr(startq ~ ztest1 ,data = calib_subset, Hess=TRUE)

#MODEL COMPARISON#
#StartQ ~ test1
model2 = polr(startq ~ test1,data = calib_subset, Hess=TRUE)

summary(model2)
(ctable <- coef(summary(model2)))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
options(scipen=999)
## combined table
(ctable <- cbind(ctable, "p value" = p))
unique(calib_subset$startq)
dim(calib_subset)
View(calib_data)
model1 = polr(startq ~ ztest1 ,data = calib_subset, Hess=TRUE)
summary(model1)
(ctable <- coef(summary(model2)))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
options(scipen=999)
## combined table
(ctable <- cbind(ctable, "p value" = p))
## test1 pvalue = 0.0007
#StartQ ~ AllP

model2 = polr(startq ~ zallP, data = calib_subset, Hess=TRUE)

model3 = polr(startq ~ allP, data = calib_subset, Hess=TRUE)
summary(model3)
(ctable <- coef(summary(model3)))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
options(scipen=999)
## combined table
(ctable <- cbind(ctable, "p value" = p))
#StartQ ~ AllP + test1 -- this model produces some issues in the polr model and won't run
model4 = polr(startq ~ allP + test1, data = calib_subset, Hess=TRUE)
#MODEL COMPARISON#
#StartQ ~ test1
model2 = polr(startq ~ test1,data = calib_subset, Hess=TRUE)

summary(model2)
(ctable <- coef(summary(model2)))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
options(scipen=999)
## combined table
(ctable <- cbind(ctable, "p value" = p))

model4 = polr(startq ~ zallP + ztest1, data = calib_subset, Hess=TRUE)
summary(model4)
(ctable <- coef(summary(model4)))

#StartQ ~ AllP
model3 = polr(startq ~ allP, data = calib_subset, Hess=TRUE)
summary(model3)
(ctable <- coef(summary(model3)))

## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
options(scipen=999)
## combined table
(ctable <- cbind(ctable, "p value" = p))

### using ordinalNet package ###
library("ordinalNet")
ordmod1 = ordinalNet(as.matrix(calib_subset$ztest1), calib_subset$startq)
summary(ordmod1)
coef(ordmod1, matrix=TRUE)
#kfold cv
set.seed(123)
ordfit1 = ordinalNetTune(as.matrix(calib_subset$ztest1), calib_subset$startq, family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
head(ordfit1$loglik)
bestLambdaIndex = which.max(rowMeans(ordfit1$loglik))
head(coef(ordfit1$fit, matrix = TRUE, whichLambda = bestLambdaIndex))
#interpretation???

View(calib_data)
?ordinalnet
?ordinalNet
View(calib_subset)
