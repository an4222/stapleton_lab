paper = (14/15)*100
finalg = sum(mid*0.15, mean(proj)*.45, final*.2, pres*.1, paper*.1)
print(finalg)
#stt grade calc
mid = 74
proj = c((14/15)*100, 100,100,100,100)
final = 80
pres = (14/15)*100
paper = (14/15)*100
finalg = sum(mid*0.15, mean(proj)*.45, final*.2, pres*.1, paper*.1)
print(finalg)
?matrix(
)
m = matrix(c(1,2,3,4,5,6,7,8,9), nrow =3 )
m\
m
flatten(m, across = "rows")
new = as.vector(m)
new
new = as.vector(as.data.frame(m)
)
new
newvector = as.vector(m)
new = as.vector(as.matrix.data.frame(m))
m = matrix(c(1,2,3,4,5,6,7,8,9), nrow =3 )
newvector = as.vector(m)
new = as.vector(as.matrix.data.frame(m))
new
?rep()
?sort()
grades
numLlvs <- 4
confusionMatrix(
factor(sample(rep(letters[1:numLlvs], 200), 50)),
factor(sample(rep(letters[1:numLlvs], 200), 50)))
install.packages("confusionMatrix")
library('caret')
numLlvs <- 4
confusionMatrix(
factor(sample(rep(letters[1:numLlvs], 200), 50)),
factor(sample(rep(letters[1:numLlvs], 200), 50)))
sample(rep(letters[1:numLlvs], 200), 50)
sample(rep(letters[1:numLlvs], 200), 50)
confusionMatrix(
factor(sample(rep(letters[1:numLlvs], 200), 50)),
factor(sample(rep(letters[1:numLlvs], 200), 50)))
library(tidyr)
library(pracma)
library(stringr)
library(tidyverse)
library(dplyr)
library(MASS)
library(glm.predict)
library(Stack)
setwd("C:/Users/twili/Desktop/GIThub/Andrew/stapleton_lab/Stress_Splicing/2018_6")
# In the case of having one CSV containing calculated derivatives, use this code:
#deriv=read.csv(file = "(YEAR_MONTH_PLATE_qPCR_output.csv", header=FALSE)
deriv_complete=read.csv(file = "2018_6_1_qPCR_Output.csv", header=FALSE)
deriv = deriv_complete
# Remove extra labels column
deriv = deriv[,-1]
# Transpose derivatives to be in equivalent format as raw plate data
deriv = as.data.frame(t(deriv), header=FALSE)
# Remove blank column (4th)
#deriv = deriv[,-5]
# Rename columns
colnames(deriv)=c("plateID", "reaction_type", "sampleID", "starting_quantity", "cpD1", "cpD2")
### Removing NTC and gblock-Minus values ###
# Indicate if sample is NTC (negative control)
deriv['sampleID_NTC'] = grepl('NTC', deriv$sampleID)
# Remove NTC samples, indicator (T/F) column, and cpD2 values
ntc = which(deriv$sampleID_NTC)
deriv = deriv[-ntc,]
deriv = deriv[,-c(6,7)]
# Indicate if sample is 'Plus' or 'Minus'
deriv['sampleID_Minus'] = grepl('minus', deriv$sampleID)
# Remove 'Minus' values (include only gblock+ values), and indicator (T/F) column
minus = which(deriv$sampleID_Minus)
deriv = deriv[-minus,]
deriv = deriv[,-6]
deriv$cpD1 = as.numeric(as.character(deriv$cpD1))
### COMPLETED INITIAL DATA FRAMING ###
##########################################################
############ Removing Ununsual Observations ##############
##########################################################
# Remove unusual observations from initial data frame (CT value less than 10)
deriv = deriv %>% filter(deriv$cpD1 >= 10)
# Read in raw cycle data - may need to combine multiple files
cycle1 = read.csv(file = "2018_6_1_plate.csv", header = FALSE)
# Create complete set of reaction data (derivative and cycle)
reaction = Stack(deriv_complete, cycle1)
# Remove repeat labeling
replace = reaction[7:10,]
reaction = reaction[-c(1:4, 7:10),]
reaction = Stack(replace, reaction)
# Transpose so column headers at top
reaction = as.data.frame(t(reaction))
reaction = reaction[,-c(6:7)]
# Replace column names with first row
colnames(reaction) <- as.character(unlist(reaction[1,]))
reaction = reaction[-1,]
colnames(reaction)[5] = "cpD1"
reaction$cpD1 = as.numeric(as.character(reaction$cpD1))
# Filter unusual observations (CT value less than 10)
unusual_obs_2018_6 = reaction %>% filter(reaction$cpD1 < 10)
# Write CSV file
#write.csv(unusual_obs_2018_6, file="Unusual_Obs_2018_6.csv")
# ### COMPLETED UNUSUAL OBSERVATIONS REMOVAL/REPORTING ###
##########################################################
################# Calibrated Data Framing ################
##########################################################
library("rowr")
# Create/Write data frame for Calibrated values
calib_data = deriv %>% filter(str_detect(sampleID, "g"))
# Sort by starting quantity
calib_data = calib_data[order(calib_data$starting_quantity),]
calib_data$starting_quantity = as.numeric(as.character(calib_data$starting_quantity))
calib_data$cpD1 = as.numeric(as.character(calib_data$cpD1))
test1 = filter(calib_data, reaction_type=="test1")[,5]
allP = filter(calib_data, reaction_type=="all_products")[,4:5]
calib_data = as.data.frame(cbind.fill(allP, test1, fill = NA))
colnames(calib_data) = c("startq", 'allP', "test1")
# Format starting quantity values as decimals, not scientific notation
calib_data$startq=as.factor(format(calib_data$startq, scientific=FALSE))
calib_data$startq=as.factor(calib_data$startq)
write.csv(calib_data, file = "calib_2018_6.csv")
### COMPLETED CALIBRATED DATA FRAME ###
##########################################################
############### Experimental Data Framing ################
##########################################################
# Create/Write data frame for Experimental values
exp_data = deriv %>% filter(str_detect(sampleID, "g")==FALSE)
# Sort by starting quantity
exp_data = exp_data[order(exp_data$starting_quantity),]
# Remove first and last rows (unnecessary labeling)
# exp_data = exp_data[-1,]
# exp_data = exp_data[-nrow(exp_data),]
exp_data$cpD1 = as.numeric(as.character(exp_data$cpD1))
# Order data by sampleID
exp_data = exp_data[order(exp_data$sampleID),]
### Finding invalid observations ###
# Find counts of each unique sampleID; for sample with a count not equal to 2, remove from data frame
counts = as.data.frame(table(exp_data$sampleID))
countsne2 = as.data.frame(filter(counts, !counts$Freq==2))
# Remove invalid observations from data set
exp_data = exp_data[!exp_data$sampleID %in% countsne2$Var1,]
### Report invalid observations ###
# Send CSV of removed sampleID's to Dr. S (invalid obs), with additional plots of raw cycle values for invalid obs
# Write CSV file to send Dr. S for investigation
### WORK ON --> add derivative values in to the CSV file
### WORK ON --> creating a separate CSV file with samples with unusual derivatives
#write.csv(file="2018_11_SamplesToInvestigate", countsne2)
#write.csv(file="YEAR_MONTH_SamplesToInvestigate", countsne2)
# Create empty vectors for for-loop to input cpD1 values
test1.exp = c()
allP.exp = c()
sampleID.exp = c()
# For loop -- iterating thru starting quantity and reaction type to return cpD1 values
for(i in 1:length(exp_data$sampleID)){
id.exp = toString(exp_data$sampleID[i])
if(i %% 2 == 1){
sampleID.exp = c(sampleID.exp, id.exp)
}
val = toString(exp_data$reaction_type[i])
if(strcmp(val, "test1")){
test1.exp = c(test1.exp, exp_data$cpD1[i])
}
if(strcmp(val, "all_products")){
allP.exp = c(allP.exp, exp_data$cpD1[i])
}
}
# Bind test1 and allProd cpD1 values by sample ID, convert to data frame
exp_data = as.data.frame(cbind(sampleID.exp, test1.exp, allP.exp))
exp_data$test1.exp = as.numeric(as.character(exp_data$test1.exp))
exp_data$allP.exp = as.numeric(as.character(exp_data$allP.exp))
## NOT FOR USE IN CAPSTONE -- USE IN COMPARISON LATER ##
startquan = as.character(calib_data$startq)
allprod = calib_data$allP
t1 = calib_data$test1
dat = data.frame(cbind(startquan,allprod,t1), stringsAsFactors = FALSE)
dat$allprod = as.numeric(dat$allprod)
dat$t1 = as.numeric(dat$t1)
#Create divide funtion - every element in column 1 divided by every element in column 2
divide <- function(col1, col2){
ratio = NULL;
for (i in col1){
ratio = c(ratio,i/col2)
}
return(ratio)
}
#Subset data by starting quantity
group = split.data.frame(dat, dat$startquan)
# Calculate combination ratios at each starting quantity
combratio = NULL;
for (k in group){
combratio = cbind(combratio, divide(k$allprod, k$t1))
}
# Create data frame with unique ratios at each starting quantity
startqvalues = rep(unique(startquan), rep(length(unique(startquan)),length(unique(startquan))))
newratios.calib = data.frame(rbind(unique(startqvalues), combratio), stringsAsFactors = FALSE)
# Duplicate newratios.calib data frame
newratios.calib = as.data.frame(newratios.calib)
colnames(newratios.calib) = c("0.01", "0.05", "0.10", "0.50", "1.00", "50.00")
newratios.calib = newratios.calib[-1,]
newratiosvector = as.numeric(as.vector(as.matrix.data.frame(newratios.calib)))
startqvector = sort(rep(unique(startquan), length(newratios.calib$`0.01`)))
newratios.calib = as.data.frame(cbind(newratiosvector, startqvector), stringsAsFactors = FALSE)
calib_data$test1 = as.numeric(as.character(calib_data$test1))
calib_data$allP = as.numeric(as.character(calib_data$allP))
adj_val = c()
allP = c()
startq = c()
ratio =calib_data$allP/calib_data$test1
# Itterating through each set of (3) observations performing U-Stats on each set of inputs
for (i in 1:(nrow(calib_data)/3)){
t_x <- c(calib_data$allP[3*i - 2], calib_data$allP[3*i - 1], calib_data$allP[3*i])
t_y <- c(calib_data$test1[3*i - 2], calib_data$test1[3*i - 1], calib_data$test1[3*i])
adj <- mean(outer(t_x, t_y, "-"))
adj_val <- c(adj_val, adj, adj, adj)
}
adjusted_test1 <- test1 + adj_val
# Append adjusted test1 values and adjustment value to data set
calib_data=cbind(calib_data,adjusted_test1,adj_val)
# Write Calibrated Data CSV --> Used in "qPCR_Plotting" code for visuals
#write.csv(file="YEAR_MONTH_Calibrated_DF", calib_data)
View(calib_data)
library(tidyr)
library(pracma)
library(stringr)
library(tidyverse)
library(dplyr)
library(MASS)
library(glm.predict)
library(Stack)
# In the case of having one CSV containing calculated derivatives, use this code:
#deriv=read.csv(file = "(YEAR_MONTH_PLATE_qPCR_output.csv", header=FALSE)
deriv_complete=read.csv(file = "2018_6_1_qPCR_Output.csv", header=FALSE)
##########################################################
################### Initial Data Framing #################
##########################################################
deriv = deriv_complete
# Remove extra labels column
deriv = deriv[,-1]
# Transpose derivatives to be in equivalent format as raw plate data
deriv = as.data.frame(t(deriv), header=FALSE)
# Remove blank column (4th)
#deriv = deriv[,-5]
# Rename columns
colnames(deriv)=c("plateID", "reaction_type", "sampleID", "starting_quantity", "cpD1", "cpD2")
### Removing NTC and gblock-Minus values ###
# Indicate if sample is NTC (negative control)
deriv['sampleID_NTC'] = grepl('NTC', deriv$sampleID)
# Remove NTC samples, indicator (T/F) column, and cpD2 values
ntc = which(deriv$sampleID_NTC)
deriv = deriv[-ntc,]
deriv = deriv[,-c(6,7)]
# Indicate if sample is 'Plus' or 'Minus'
deriv['sampleID_Minus'] = grepl('minus', deriv$sampleID)
# Remove 'Minus' values (include only gblock+ values), and indicator (T/F) column
minus = which(deriv$sampleID_Minus)
deriv = deriv[-minus,]
deriv = deriv[,-6]
deriv$cpD1 = as.numeric(as.character(deriv$cpD1))
### COMPLETED INITIAL DATA FRAMING ###
##########################################################
############ Removing Ununsual Observations ##############
##########################################################
# Remove unusual observations from initial data frame (CT value less than 10)
deriv = deriv %>% filter(deriv$cpD1 >= 10)
# Read in raw cycle data - may need to combine multiple files
cycle1 = read.csv(file = "2018_6_1_plate.csv", header = FALSE)
# Create complete set of reaction data (derivative and cycle)
reaction = Stack(deriv_complete, cycle1)
# Remove repeat labeling
replace = reaction[7:10,]
reaction = reaction[-c(1:4, 7:10),]
reaction = Stack(replace, reaction)
# Transpose so column headers at top
reaction = as.data.frame(t(reaction))
reaction = reaction[,-c(6:7)]
# Replace column names with first row
colnames(reaction) <- as.character(unlist(reaction[1,]))
reaction = reaction[-1,]
colnames(reaction)[5] = "cpD1"
reaction$cpD1 = as.numeric(as.character(reaction$cpD1))
# Filter unusual observations (CT value less than 10)
unusual_obs_2018_6 = reaction %>% filter(reaction$cpD1 < 10)
# Write CSV file
#write.csv(unusual_obs_2018_6, file="Unusual_Obs_2018_6.csv")
# ### COMPLETED UNUSUAL OBSERVATIONS REMOVAL/REPORTING ###
##########################################################
################# Calibrated Data Framing ################
##########################################################
library("rowr")
# Create/Write data frame for Calibrated values
calib_data = deriv %>% filter(str_detect(sampleID, "g"))
# Sort by starting quantity
calib_data = calib_data[order(calib_data$starting_quantity),]
calib_data$starting_quantity = as.numeric(as.character(calib_data$starting_quantity))
calib_data$cpD1 = as.numeric(as.character(calib_data$cpD1))
test1 = filter(calib_data, reaction_type=="test1")[,5]
allP = filter(calib_data, reaction_type=="all_products")[,4:5]
#Combine test1 and allP obs, with NA in blank cells
calib_data = as.data.frame(cbind.fill(allP, test1, fill = NA))
colnames(calib_data) = c("startq", 'allP', "test1")
# Format starting quantity values as decimals, not scientific notation
calib_data$startq=as.factor(format(calib_data$startq, scientific=FALSE))
calib_data$startq=as.factor(calib_data$startq)
write.csv(calib_data, file = "calib_2018_6.csv")
### COMPLETED CALIBRATED DATA FRAME ###
##########################################################
############### Experimental Data Framing ################
##########################################################
# Create/Write data frame for Experimental values
exp_data = deriv %>% filter(str_detect(sampleID, "g")==FALSE)
# Sort by starting quantity
exp_data = exp_data[order(exp_data$starting_quantity),]
# Remove first and last rows (unnecessary labeling)
# exp_data = exp_data[-1,]
# exp_data = exp_data[-nrow(exp_data),]
exp_data$cpD1 = as.numeric(as.character(exp_data$cpD1))
# Order data by sampleID
exp_data = exp_data[order(exp_data$sampleID),]
### Finding invalid observations ###
# Find counts of each unique sampleID; for sample with a count not equal to 2, remove from data frame
counts = as.data.frame(table(exp_data$sampleID))
countsne2 = as.data.frame(filter(counts, !counts$Freq==2))
# Remove invalid observations from data set
exp_data = exp_data[!exp_data$sampleID %in% countsne2$Var1,]
### Report invalid observations ###
# Send CSV of removed sampleID's to Dr. S (invalid obs), with additional plots of raw cycle values for invalid obs
# Write CSV file to send Dr. S for investigation
### WORK ON --> add derivative values in to the CSV file
### WORK ON --> creating a separate CSV file with samples with unusual derivatives
#write.csv(file="2018_11_SamplesToInvestigate", countsne2)
#write.csv(file="YEAR_MONTH_SamplesToInvestigate", countsne2)
# Create empty vectors for for-loop to input cpD1 values
test1.exp = c()
allP.exp = c()
sampleID.exp = c()
# For loop -- iterating thru starting quantity and reaction type to return cpD1 values
for(i in 1:length(exp_data$sampleID)){
id.exp = toString(exp_data$sampleID[i])
if(i %% 2 == 1){
sampleID.exp = c(sampleID.exp, id.exp)
}
val = toString(exp_data$reaction_type[i])
if(strcmp(val, "test1")){
test1.exp = c(test1.exp, exp_data$cpD1[i])
}
if(strcmp(val, "all_products")){
allP.exp = c(allP.exp, exp_data$cpD1[i])
}
}
# Bind test1 and allProd cpD1 values by sample ID, convert to data frame
exp_data = as.data.frame(cbind(sampleID.exp, test1.exp, allP.exp))
exp_data$test1.exp = as.numeric(as.character(exp_data$test1.exp))
exp_data$allP.exp = as.numeric(as.character(exp_data$allP.exp))
write.csv(exp_data, file = "exp_2018_6.csv")
### COMPLETED EXPERIMENTAL DATA FRAME ###
##########################################################
############### Combination Ratios for qPCR ##############
##########################################################
## NOT FOR USE IN CAPSTONE -- USE IN COMPARISON LATER ##
startquan = as.character(calib_data$startq)
allprod = calib_data$allP
t1 = calib_data$test1
dat = data.frame(cbind(startquan,allprod,t1), stringsAsFactors = FALSE)
dat$allprod = as.numeric(dat$allprod)
dat$t1 = as.numeric(dat$t1)
#Create divide funtion - every element in column 1 divided by every element in column 2
divide <- function(col1, col2){
ratio = NULL;
for (i in col1){
ratio = c(ratio,i/col2)
}
return(ratio)
}
#Subset data by starting quantity
group = split.data.frame(dat, dat$startquan)
# Calculate combination ratios at each starting quantity
combratio = NULL;
for (k in group){
combratio = cbind(combratio, divide(k$allprod, k$t1))
}
# Create data frame with unique ratios at each starting quantity
startqvalues = rep(unique(startquan), rep(length(unique(startquan)),length(unique(startquan))))
newratios.calib = data.frame(rbind(unique(startqvalues), combratio), stringsAsFactors = FALSE)
# Duplicate newratios.calib data frame
newratios.calib = as.data.frame(newratios.calib)
colnames(newratios.calib) = c("0.01", "0.05", "0.10", "0.50", "1.00", "50.00")
newratios.calib = newratios.calib[-1,]
newratiosvector = as.numeric(as.vector(as.matrix.data.frame(newratios.calib)))
startqvector = sort(rep(unique(startquan), length(newratios.calib$`0.01`)))
newratios.calib = as.data.frame(cbind(newratiosvector, startqvector), stringsAsFactors = FALSE)
#################### end combination ratios #####################
### CONFUSTION MATRIX ###
library(caret)
numLlvs <- 4
confusionMatrix(
factor(sample(rep(letters[1:numLlvs], 200), 50)),
factor(sample(rep(letters[1:numLlvs], 200), 50)))
View(calib_data)
##### Finding the average adjusted test 1 #########
## CREATE DATA FRAME WITH ONLY S.Q. AND ADJUSTMENT VAL ##
calib_adj = calib_data[,c(1,6)]
##finding ajustment value##
group = split.data.frame(calib_data, calib_data$startq)
group
mean(c(1,2,3))
ave(c(1,2,3))
adj <- function(AllP, Test1){
adjust = NULL;
for (i in group){
adjust = c(adjust,ave(AllP)-ave(Test1))
}
return(adjust)
}
x = (1,2,3)
x = c(1,2,3)
y = c(3,4,5)
adj(x,y)
adj <- function(AllP, Test1){
adjust = NULL;
for (i in group){
adjust = c(adjust,mean(AllP)-mean(Test1))
}
return(adjust)
}
adj(x,y)
adj <- function(AllP, Test1){
adjust = mean(AllP)-mean(Test1)
return(adjust)
}
adj(x,y)
apply(group, adj)
?apply()
for (k in group){
adj(k)
}
for (k in group){
adj(k$allP, k$test1)
}
for (k in group){
print(adj(k$allP, k$test1))
}
adjust = NULL
for (k in group){
adjust = c(adjust,adj(k$allP, k$test1))
}
adjust
adjval = NULL
for (k in group){
adjval = c(adjval,adj(k$allP, k$test1))
}
calib_data$adjval = NULL
for (k in group){
calib_data$adjval = c(calib_data$adjval,adj(k$allP, k$test1))
}
adj <- function(AllP, Test1){
adjust = ave(AllP)-ave(Test1)
return(adjust)
}
calib_data$adjval = NULL
for (k in group){
calib_data$adjval = c(calib_data$adjval,adj(k$allP, k$test1))
}
adj(x,y)
adj <- function(AllP, Test1){
adjust = ave(AllP)-ave(Test1)
return(adjust)
}
adjval = NULL
for (k in group){
adjval = c(adjval,adj(k$allP, k$test1))
}
adjval
calib_data$adjval = adjval
x+y
calib_data$adjusted_test1 = calib_data$test1 + adjval
average <- function(col1){
avg = NULL;
for (i in col1){
avg = c(avg,mean(col1))
}
return(avg)
}
group = split.data.frame(calib_data, calib_data$startq)
adj.test1.avg = NULL;
for (k in group){
adj.test1.avg = c(adj.test1.avg, average(k$adjusted_test1))
}
print(adj.test1.avg)
calib_adj = as.data.frame(unique(cbind(as.character(calib_data$startq), adj.test1.avg)))
calib_adj = cbind(calib_data$startq, adj.test1.avg)
View(calib_adj)
class(calib_adj[,2])
calib_adj = cbind(as.factor(as.character(calib_data$startq)), adj.test1.avg)
calib_adj = cbind(as.numeric(as.character(calib_data$startq)), adj.test1.avg)
# Rename columns
colnames(calib_adj)=c("startq", "adj.test1.avg")
# Rename columns
colnames(calib_adj)=c("startq", "adj.test1.avg")
names(calib_adj)
calib_adj = as.data.frame(cbind(as.numeric(as.character(calib_data$startq)), adj.test1.avg))
# Rename columns
colnames(calib_adj)=c("startq", "adj.test1.avg")
unique(calib_adj)
calib_adj = unique(as.data.frame(cbind(as.numeric(as.character(calib_data$startq)), adj.test1.avg)))
# Rename columns
colnames(calib_adj)=c("startq", "adj.test1.avg")
setwd("C:/Users/twili/Desktop/GIThub/Andrew/stapleton_lab/Stress_Splicing/2018_11")
